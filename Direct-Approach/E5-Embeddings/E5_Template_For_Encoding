{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V5E1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["This notebook refers to \"SBERT,\" but in fact we actually use E5 for all embeddings. Please disregard this error."],"metadata":{"id":"-mEibhyI1MHs"}},{"cell_type":"markdown","source":["Below I have created a template to encode sentences/chunks with SBERT:\n","\n","NOTE: Please remember that we are using the SBERT model from this huggingface link: https://huggingface.co/intfloat/e5-base-v2. This model embeds in a 768 dimensional space.\n","\n","**Also** note that I DO NOT normalize the embeddings since we already have code in Anya's clustering to normalize embeddings. I think it is best that we only normalize once and use the same normalization to ensure consistency and reproducability.\n"],"metadata":{"id":"8XBN5rzjNmYa"}},{"cell_type":"code","source":["#set up\n","!pip install openpyxl\n","import openpyxl\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor\n","from transformers import AutoTokenizer, AutoModel,logging\n","import pandas as pd\n","import numpy as np\n","from google.colab import drive\n","import hashlib\n","\n","\n","drive.mount('/content/drive')\n","model_name = \"intfloat/e5-base-v2\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model=AutoModel.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ozOvE_vqCDeP","executionInfo":{"status":"ok","timestamp":1761250416505,"user_tz":360,"elapsed":8376,"user":{"displayName":"Josh Schultze","userId":"02185956454341759681"}},"outputId":"61f063ab-7bc4-4642-bc5d-c471b7dd1ef1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openpyxl\n","  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n","Collecting et-xmlfile (from openpyxl)\n","  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n","Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/250.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n","Installing collected packages: et-xmlfile, openpyxl\n","Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["#Load in data\n","dfExcel = pd.read_excel(\"/content/drive/MyDrive/full_clean.xlsx\")\n","dfExcel.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"KJBDUWqFKrZz","executionInfo":{"status":"ok","timestamp":1761250418885,"user_tz":360,"elapsed":2373,"user":{"displayName":"Josh Schultze","userId":"02185956454341759681"}},"outputId":"ceb69914-edd1-42dd-c18d-16d4069822ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                  date                                              title  \\\n","0  2024-05-01 12:03:00  Everyone's an Expert: How to Empower Your Empl...   \n","1  2025-08-21 13:53:34  Why Certified VMware Pros Are Driving the Futu...   \n","2  2024-10-03 12:59:00  Defunct' DOJ ransomware task force raises ques...   \n","3  2025-03-26 11:25:00  Sparring in the Cyber Ring: Using Automated Pe...   \n","4  2025-05-14 15:42:00  Open source project curl is sick of users subm...   \n","\n","             source                                            article  \n","0     thehackernews  \\n\\n\\n\\nThere's a natural human desire to avoi...  \n","1  bleepingcomputer  \\n\\nBy Brenda Emerson, VMUG President\\n\\nIT is...  \n","2        techtarget  \\n\\nListen to this article. This audio was gen...  \n","3     thehackernews  \"A boxer derives the greatest advantage from h...  \n","4       arstechnica  \"A threshold has been reached. We are effectiv...  "],"text/html":["\n","  <div id=\"df-edbd5c9b-e7ca-4bf5-832d-d58ee50a29b7\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>date</th>\n","      <th>title</th>\n","      <th>source</th>\n","      <th>article</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2024-05-01 12:03:00</td>\n","      <td>Everyone's an Expert: How to Empower Your Empl...</td>\n","      <td>thehackernews</td>\n","      <td>\\n\\n\\n\\nThere's a natural human desire to avoi...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2025-08-21 13:53:34</td>\n","      <td>Why Certified VMware Pros Are Driving the Futu...</td>\n","      <td>bleepingcomputer</td>\n","      <td>\\n\\nBy Brenda Emerson, VMUG President\\n\\nIT is...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2024-10-03 12:59:00</td>\n","      <td>Defunct' DOJ ransomware task force raises ques...</td>\n","      <td>techtarget</td>\n","      <td>\\n\\nListen to this article. This audio was gen...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2025-03-26 11:25:00</td>\n","      <td>Sparring in the Cyber Ring: Using Automated Pe...</td>\n","      <td>thehackernews</td>\n","      <td>\"A boxer derives the greatest advantage from h...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2025-05-14 15:42:00</td>\n","      <td>Open source project curl is sick of users subm...</td>\n","      <td>arstechnica</td>\n","      <td>\"A threshold has been reached. We are effectiv...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edbd5c9b-e7ca-4bf5-832d-d58ee50a29b7')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-edbd5c9b-e7ca-4bf5-832d-d58ee50a29b7 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-edbd5c9b-e7ca-4bf5-832d-d58ee50a29b7');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-81da7f00-b599-4b65-98e6-ccf7e3c26913\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81da7f00-b599-4b65-98e6-ccf7e3c26913')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-81da7f00-b599-4b65-98e6-ccf7e3c26913 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"dfExcel","summary":"{\n  \"name\": \"dfExcel\",\n  \"rows\": 13075,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 12719,\n        \"samples\": [\n          \"2024-04-01 19:10:23\",\n          \"2024-11-11 19:10:58\",\n          \"2025-05-01 11:11:40\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12732,\n        \"samples\": [\n          \"Reframing the ZTNA vs. SASE Debate\",\n          \"Cisco warns of max severity flaw in Firewall Management Center\",\n          \"Some Data Is \\u2018Breached\\u2019 During a Hacking Attack on the Alabama Education Department\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 46,\n        \"samples\": [\n          \"industrialcyber\",\n          \"checkpoint\",\n          \"wired\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13075,\n        \"samples\": [\n          \"Security researchers at Trend Micro are flagging problems with Nvidia\\u2019s patch for a critical vulnerability in the Nvidia Container Toolkit, warning that the incomplete mitigation leaves enterprises exposed to container escape attacks.\\n\\nThe flaw, tagged as CVE-2024-0132 with a CVSS score of 9/10, was patched last September as a high-priority issue but now comes word from Trend Micro that the patch is \\u201cincomplete\\u201d and left the door ajar for hackers to execute arbitrary commands, compromise sensitive data, or escalate privileges on an affected system.\\n\\nAccording to Trend Micro\\u2019s analysis, a specially crafted container can exploit the TOCTOU timing window between when a container\\u2019s access to the host file system is checked and when the access is actually executed.\\n\\nThis gap allows an attacker to inject operations that bypass the intended isolation, effectively letting the container access or manipulate host resources. The oversight here lies in the patch\\u2019s inability to enforce strict checks that would preclude this race condition in the container\\u2019s runtime, Trend Micro explained.\\n\\n\\u201cExploiting these vulnerabilities could enable attackers to access sensitive host data or cause significant operational disruption by exhausting host resources,\\u201d Trend Micro said in its documentation of the faulty patch.\\n\\n\\u201cSuccessful exploitation could lead to unauthorized access to sensitive host data, theft of proprietary AI models or intellectual property, severe operational disruptions, and prolonged downtime due to resource exhaustion or system inaccessibility.\\u201d\\n\\nThe security company said organizations utilizing the NVIDIA Container Toolkit or Docker in AI, cloud, or containerized environments are directly affected, particularly those using default configurations or specific toolkit features introduced in recent versions.\\n\\n\\u201cCompanies deploying AI workloads or Docker-based container infrastructure are potentially at risk,\\u201d the company added.\\n\\nAdvertisement. Scroll to continue reading.\\n\\nAccording to Trend Micro\\u2019s analysis, versions up to 1.17.3 of the toolkit are inherently vulnerable, while version 1.17.4 requires an explicit enabling of the feature allow-cuda-compat-libs-from-container to be exploitable.\\n\\nIn addition, Trend Micro said it uncovered an adjacent denial-of-service flaw linked to Docker on Linux systems. Containers configured with multiple mounts using bind-propagation (specifically those with the shared flag) could trigger unchecked growth in the Linux mount table.\\n\\nTrend Micro said the resulting exhaustion of file descriptors poses a serious denial-of-service risk, effectively stalling container creation and denying remote connectivity via SSH.\\n\\nThe company is urging enterprise users to limit the Docker API to authorized personnel only and avoid unnecessary root-level privileges and to disable optional features in the NVIDIA Container Toolkit unless they are strictly required.\\n\\nAccording to documentation from cloud security vendor Wiz, the flaw threatens more than 35% of cloud environments using Nvidia GPUs, allowing attackers to escape containers and take control of the underlying host system. The impact is far-reaching, given the prevalence of Nvidia\\u2019s GPU solutions in both cloud and on-premises AI operations.\\n\\nRelated: Critical Nvidia Flaw Exposes Cloud AI Systems to Host Takeover\\n\\nRelated: Nvidia Patches High-Severity Vulnerabilities in AI, Networking Products\\n\\nRelated: Nvidia Patches High-Severity GPU Driver Vulnerabilities\\n\\nRelated: Code Execution Flaws Haunt NVIDIA ChatRTX for Windows\\n\\nRelated: SAP AI Core Flaws Allowed Service Takeover, Customer Data Access\",\n          \"Japan's National Police Agency (NPA) and National Center of Incident Readiness and Strategy for Cybersecurity (NCSC) accused a China-linked threat actor named MirrorFace of orchestrating a persistent attack campaign targeting organizations, businesses, and individuals in the country since 2019.\\n\\nThe primary objective of the attack campaign is to steal information related to Japan's national security and advanced technology, the agencies said.\\n\\nMirrorFace, also tracked as Earth Kasha, is assessed to be a sub-group within APT10. It has a track record of systematically striking Japanese entities, often leveraging tools like ANEL, LODEINFO, and NOOPDOOR (aka HiddenFace).\\n\\nLast month, Trend Micro revealed details of a spear-phishing campaign that targeted individuals and organizations in Japan with an aim to deliver ANEL and NOOPDOOR. Other campaigns observed in recent years have also been directed against Taiwan and India.\\n\\nAccording to NPA and NCSC, attacks mounted by MirrorFace have been broadly categorized into three major campaigns -\\n\\nCampaign A (From December 2019 to July 2023), targeting think tanks, governments, politicians, and media organizations using spear-phishing emails to deliver LODEINFO, NOOPDOOR, and LilimRAT (a custom version of the open-source Lilith RAT)\\n\\n(From December 2019 to July 2023), targeting think tanks, governments, politicians, and media organizations using spear-phishing emails to deliver LODEINFO, NOOPDOOR, and LilimRAT (a custom version of the open-source Lilith RAT) Campaign B (From February to October 2023), targeting semiconductor, manufacturing, communications, academic, and aerospace sectors by exploiting known vulnerabilities in internet-facing Array Networks, Citrix, and Fortinet devices to breach networks to deliver Cobalt Strike Beacon, LODEINFO, and NOOPDOOR\\n\\n(From February to October 2023), targeting semiconductor, manufacturing, communications, academic, and aerospace sectors by exploiting known vulnerabilities in internet-facing Array Networks, Citrix, and Fortinet devices to breach networks to deliver Cobalt Strike Beacon, LODEINFO, and NOOPDOOR Campaign C (From June 2024), targeting academia, think tanks, politicians, and media organizations using spear-phishing emails to deliver ANEL.\\n\\nThe agencies also noted that they observed instances where the attackers stealthily executed the malicious payloads stored on the host computer within the Windows Sandbox and have communicated with a command-and-control server since at least June 2023.\\n\\n\\\"This method allows malware to be executed without being monitored by antivirus software or EDR on the host computer, and when the host computer is shut down or restarted, traces in the Windows Sandbox are erased, so evidence is not left behind,\\\" the NPA and NCSC said.\",\n          \"To quash speculation of a cyberattack or BGP hijack incident causing the recent 1.1.1.1 Resolver service outage, Cloudflare explains in a post mortem that the incident was caused by an internal misconfiguration.\\n\\nThe outage occurred on July 14 and impacted most users of the service all over the world, rendering internet services unavailable in many cases.\\n\\n\\u201cThe root cause was an internal configuration error and not the result of an attack or a BGP hijack,\\u201d Cloudflare says in the announcement.\\n\\nThis statement comes after people reported on social media that the outage was caused by a BGP hijack.\\n\\nGlobal outage unfolding\\n\\nCloudflare's 1.1.1.1 public DNS resolver launched in 2018 promising a private and fast internet connectivity service to users worldwide.\\n\\nThe company explains that behind the outage was a configuration change for a future Data Localization Suite (DLS) performed on June 6, which mistakenly linked 1.1.1.1 Resolver IP prefixes to a non-production DLS service.\\n\\nOn July 14 at 21:48 UTC, a new update added a test location to the inactive DLS service, refreshing the network configuration globally and applying the misconfiguration.\\n\\nThis withdrew 1.1.1.1 Resolver prefixes from Cloudflare\\u2019s production data centers and routed them to a single offline location, making the service globally unreachable.\\n\\nLess than four minutes later, DNS traffic to the 1.1.1.1 Resolver began to drop. By 22:01 UTC, Cloudflare detected the incident and disclosed it to the public.\\n\\nThe misconfiguration was reverted at 22:20 UTC, and Cloudflare began re-advertising the withdrawn BGP prefixes. Finally, full service restoration at all locations was achieved at 22:54 UTC.\\n\\nThe incident affected multiple IP ranges, including 1.1.1.1 (main public DNS resolver), 1.0.0.1 (secondary public DNS resolver), 2606:4700:4700::1111 and 2606:4700:4700::1001 (main and secondary IPv6 DNS resolvers, and multiple IP ranges that support routing within Cloudflare infrastructure.\\n\\nOutage impacting key IP ranges\\n\\nSource: Cloudflare\\n\\nRegarding the incident\\u2019s impact on protocols, UDP, TCP, and DNS-over-TLS (DoT) queries to the above addresses saw a significant drop in volume, but DNS-over-HTTPS (DoH) traffic was largely unaffected as it follows a different routing via cloudflare-dns.com.\\n\\nIncident's impact for each protocol\\n\\nSource: Cloudflare\\n\\nNext steps\\n\\nThe misconfiguration could have been rejected if Cloudflare had used a system that performed progressive rollout, the internet giant admits, blaming the use of legacy systems for this failure.\\n\\nFor this reason, it plans to deprecate legacy systems and accelerate migration to newer configuration systems that utilize abstract service topologies instead of static IP bindings, allowing for gradual deployment, health monitoring at each stage, and quick rollbacks in the event that issues arise.\\n\\nCloudflare also points out that the misconfiguration had passed peer review and wasn\\u2019t caught due to insufficient internal documentation of service topologies and routing behavior, an area that the company also plans to improve.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["So first we have to chunk all of the articles. This follows Ayush's code fairly closely.\n","\n","# **Chunking:**"],"metadata":{"id":"YueN98s_KI3r"}},{"cell_type":"markdown","source":["## Pre-processing"],"metadata":{"id":"sFUlWC8PLQvG"}},{"cell_type":"code","source":["#creating a function that formats our data in a suitable way to be inputted into functions below\n","#converting each row in the og df to a dictionary with 5 keys: article id, text, source, date, and title\n","def df_to_articles(df, include_title=True):\n","    \"\"\"Convert dataframe into list of dicts usable by chunk_corpus.\"\"\"\n","    records = []\n","    for i, row in df.iterrows():\n","        # combine title + article body for richer context\n","        text = f\"{row['title']}\\n\\n{row['article']}\" if include_title else row['article']\n","        records.append({\n","            \"article_id\": i,\n","            \"text\": text,\n","            \"source\": row.get(\"source\", \"\"),\n","            \"date\": row.get(\"date\", \"\"),\n","            \"title\": row.get(\"title\", \"\"),\n","        })\n","    return records\n","\n","articles = df_to_articles(dfExcel)\n","print(articles[0].keys())"],"metadata":{"id":"7-n2TsAzKOL4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761250430941,"user_tz":360,"elapsed":482,"user":{"displayName":"Josh Schultze","userId":"02185956454341759681"}},"outputId":"fe94ce08-a676-402a-c812-7d7426ac1abc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['article_id', 'text', 'source', 'date', 'title'])\n"]}]},{"cell_type":"markdown","source":["## Chunking Function <br /><br />\n","\n","\n","**logging.set_verbosity_error() explanation**\n","\n","Hugging face throws a warning in chunk_article_by_token() bc it checks token length before we manually slice it (which we do). To avoid confusion, I used logging.set_verbosity_error() which disables all system warnings that are not errors or 'above'"],"metadata":{"id":"dC9hNu5LW0bj"}},{"cell_type":"code","source":["#chunk func that is meant to be implemented per article\n","\n","\n","def chunk_article_by_tokens(text: str, tokenizer, max_len: int = 512, stride: int = 96):\n","    if not isinstance(text, str) or not text.strip():\n","      return []\n","\n","    enc = tokenizer(\n","        text, #returns regular lists as opposed to tensors or smth else\n","        truncation=False,      # we'll window manually\n","        padding=False,\n","        return_attention_mask=False,\n","        return_tensors=None\n","    )\n","\n","    input_ids = enc[\"input_ids\"]\n","    total_len = len(input_ids)\n","    windows = [] #initialize a list\n","    # this will eventually be a list of dictionaries, each dictionary will represent a chunk\n","    start = 0\n","    chunk_id = 0\n","\n","    #looping while the starting token id < length of the article (avoid article overlap btwn chunks)\n","    while start < total_len:\n","      end = min(start + max_len, total_len) #set to end of current chunk/len(article)\n","      win_ids = input_ids[start:end]\n","      windows.append({\n","          \"chunk_id\": chunk_id,\n","          \"input_ids\": win_ids,\n","          \"attention_mask\": [1] * len(win_ids),\n","          \"start_token\": start,\n","          \"end_token\": end\n","      })\n","      if end == total_len:\n","        break\n","      start = end - stride\n","      chunk_id += 1\n","    return windows\n","\n","logging.set_verbosity_error() #see above for explanation"],"metadata":{"id":"jxkKkZ76Lc2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def chunk_corpus(articles, tokenizer, max_len=300, stride=75):\n","    all_chunks = []\n","    for art in articles:\n","        a_id = art[\"article_id\"]\n","        text = art[\"text\"]\n","        windows = chunk_article_by_tokens(text, tokenizer, max_len, stride)\n","\n","        #adding metadata to each chunk\n","        for w in windows:\n","          w.update({\n","              \"article_id\": a_id,\n","              \"title\": art.get(\"title\", \"\"),\n","              \"source\": art.get(\"source\", \"\"),\n","              \"date\": art.get(\"date\", \"\")\n","          })\n","          all_chunks.append(w)\n","    return all_chunks\n","\n","all_chunks=chunk_corpus(articles, tokenizer=tokenizer, max_len=300, stride=75)\n","print(len(all_chunks))\n","print(all_chunks[0].keys())\n"],"metadata":{"id":"w2U5IxW5PLTe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761250459989,"user_tz":360,"elapsed":25295,"user":{"displayName":"Josh Schultze","userId":"02185956454341759681"}},"outputId":"336d7b86-04aa-48ce-e439-d59ca6313be0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["50511\n","dict_keys(['chunk_id', 'input_ids', 'attention_mask', 'start_token', 'end_token', 'article_id', 'title', 'source', 'date'])\n"]}]},{"cell_type":"markdown","source":["Let's take a look at the chunks"],"metadata":{"id":"R_9LEeFuSDD0"}},{"cell_type":"code","source":["all_chunks[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-PFHBlKSGNT","executionInfo":{"status":"ok","timestamp":1761250460011,"user_tz":360,"elapsed":17,"user":{"displayName":"Josh Schultze","userId":"02185956454341759681"}},"outputId":"41f8bbc0-2ba5-463d-f0df-6168220dc96e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'chunk_id': 0,\n","  'input_ids': [101,\n","   3071,\n","   1005,\n","   1055,\n","   2019,\n","   6739,\n","   1024,\n","   2129,\n","   2000,\n","   7861,\n","   11452,\n","   2115,\n","   5126,\n","   2005,\n","   16941,\n","   3366,\n","   10841,\n","   15780,\n","   3112,\n","   2045,\n","   1005,\n","   1055,\n","   1037,\n","   3019,\n","   2529,\n","   4792,\n","   2000,\n","   4468,\n","   8701,\n","   16820,\n","   1012,\n","   1996,\n","   19728,\n","   1010,\n","   1997,\n","   2607,\n","   1010,\n","   2003,\n","   2065,\n","   2017,\n","   3246,\n","   2000,\n","   18759,\n","   2151,\n","   7367,\n","   14905,\n","   23078,\n","   1997,\n","   3036,\n","   1010,\n","   2017,\n","   1005,\n","   2310,\n","   2288,\n","   2000,\n","   3961,\n","   4810,\n","   2000,\n","   14323,\n","   2216,\n","   2200,\n","   2168,\n","   8767,\n","   1012,\n","   2004,\n","   1037,\n","   3247,\n","   1011,\n","   9338,\n","   2005,\n","   2115,\n","   3029,\n","   1010,\n","   2017,\n","   2113,\n","   2023,\n","   2092,\n","   1012,\n","   2021,\n","   2053,\n","   3043,\n","   2129,\n","   2116,\n","   8519,\n","   2030,\n","   9480,\n","   16941,\n","   3366,\n","   10841,\n","   15780,\n","   5906,\n","   2115,\n","   3029,\n","   2038,\n","   1037,\n","   3061,\n","   3457,\n","   1010,\n","   2017,\n","   1005,\n","   2128,\n","   2069,\n","   2004,\n","   5851,\n","   2004,\n","   2115,\n","   5410,\n","   4355,\n","   4957,\n","   1012,\n","   2045,\n","   1005,\n","   1055,\n","   2145,\n","   2028,\n","   2177,\n","   2008,\n","   2064,\n","   21089,\n","   2330,\n","   1996,\n","   6733,\n","   2000,\n","   18162,\n","   5081,\n","   5889,\n","   1517,\n","   2115,\n","   2219,\n","   2111,\n","   1012,\n","   3036,\n","   2442,\n","   2022,\n","   2117,\n","   3267,\n","   2005,\n","   2115,\n","   2034,\n","   2240,\n","   1997,\n","   3639,\n","   2005,\n","   2115,\n","   3029,\n","   2000,\n","   25220,\n","   1010,\n","   2017,\n","   2342,\n","   5214,\n","   5126,\n","   1012,\n","   2044,\n","   2035,\n","   1010,\n","   2027,\n","   1005,\n","   2128,\n","   2115,\n","   3120,\n","   2005,\n","   2307,\n","   4784,\n","   1010,\n","   8144,\n","   1010,\n","   1998,\n","   13749,\n","   2368,\n","   18518,\n","   1012,\n","   2174,\n","   1010,\n","   2027,\n","   1005,\n","   2128,\n","   2036,\n","   2529,\n","   1012,\n","   1998,\n","   4286,\n","   2024,\n","   2991,\n","   7028,\n","   1012,\n","   23307,\n","   2015,\n","   3305,\n","   2053,\n","   2028,\n","   2003,\n","   3819,\n","   1010,\n","   1998,\n","   2008,\n","   1005,\n","   1055,\n","   10785,\n","   2054,\n","   2027,\n","   6148,\n","   2000,\n","   18077,\n","   1012,\n","   2023,\n","   2003,\n","   2339,\n","   2115,\n","   2111,\n","   2442,\n","   2468,\n","   2115,\n","   2034,\n","   2240,\n","   1997,\n","   3639,\n","   2114,\n","   16941,\n","   8767,\n","   1012,\n","   2021,\n","   2000,\n","   2079,\n","   2061,\n","   1010,\n","   2027,\n","   2342,\n","   2000,\n","   4553,\n","   2129,\n","   2000,\n","   6985,\n","   3209,\n","   2114,\n","   1996,\n","   29461,\n","   15395,\n","   2854,\n","   1997,\n","   23307,\n","   2015,\n","   1012,\n","   2008,\n","   1005,\n","   1055,\n","   2073,\n","   3036,\n","   7073,\n","   2731,\n","   1006,\n","   2938,\n","   1007,\n","   3310,\n","   1999,\n","   1012,\n","   2054,\n","   2003,\n","   3036,\n","   7073,\n","   2731,\n","   1006,\n","   2938,\n","   1007,\n","   1029,\n","   1996,\n","   3452,\n","   7863,\n","   1997,\n","   2019,\n","   2938,\n","   2565,\n","   2003,\n","   2000,\n","   2562,\n","   2115,\n","   5126,\n","   1998,\n","   3029,\n","   5851,\n","   1012,\n","   1996,\n","   10318,\n","   5770,\n","   1010,\n","   2174,\n","   1010,\n","   2003,\n","   14313,\n","   12646,\n","   1012,\n","   2096,\n","   4180,\n","   2089,\n","   11234,\n","   2013,\n","   2565,\n","   2000,\n","   2565,\n","   1010],\n","  'attention_mask': [1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1],\n","  'start_token': 0,\n","  'end_token': 300,\n","  'article_id': 0,\n","  'title': \"Everyone's an Expert: How to Empower Your Employees for Cybersecurity Success\",\n","  'source': 'thehackernews',\n","  'date': '2024-05-01 12:03:00'},\n"," {'chunk_id': 1,\n","  'input_ids': [1010,\n","   2027,\n","   2342,\n","   2000,\n","   4553,\n","   2129,\n","   2000,\n","   6985,\n","   3209,\n","   2114,\n","   1996,\n","   29461,\n","   15395,\n","   2854,\n","   1997,\n","   23307,\n","   2015,\n","   1012,\n","   2008,\n","   1005,\n","   1055,\n","   2073,\n","   3036,\n","   7073,\n","   2731,\n","   1006,\n","   2938,\n","   1007,\n","   3310,\n","   1999,\n","   1012,\n","   2054,\n","   2003,\n","   3036,\n","   7073,\n","   2731,\n","   1006,\n","   2938,\n","   1007,\n","   1029,\n","   1996,\n","   3452,\n","   7863,\n","   1997,\n","   2019,\n","   2938,\n","   2565,\n","   2003,\n","   2000,\n","   2562,\n","   2115,\n","   5126,\n","   1998,\n","   3029,\n","   5851,\n","   1012,\n","   1996,\n","   10318,\n","   5770,\n","   1010,\n","   2174,\n","   1010,\n","   2003,\n","   14313,\n","   12646,\n","   1012,\n","   2096,\n","   4180,\n","   2089,\n","   11234,\n","   2013,\n","   2565,\n","   2000,\n","   2565,\n","   1010,\n","   2087,\n","   2024,\n","   3227,\n","   2714,\n","   1010,\n","   9034,\n","   2115,\n","   5126,\n","   2000,\n","   3422,\n","   22892,\n","   6876,\n","   1010,\n","   2817,\n","   12391,\n","   18216,\n","   1010,\n","   1998,\n","   2202,\n","   5852,\n","   2006,\n","   16941,\n","   1000,\n","   19548,\n","   1012,\n","   1000,\n","   2012,\n","   2037,\n","   4563,\n","   1010,\n","   2938,\n","   3454,\n","   2024,\n","   2881,\n","   2000,\n","   2393,\n","   2017,\n","   1024,\n","   16957,\n","   2115,\n","   5126,\n","   2006,\n","   14622,\n","   16941,\n","   3366,\n","   10841,\n","   15780,\n","   10831,\n","   2107,\n","   2004,\n","   13569,\n","   12227,\n","   1998,\n","   16540,\n","   8059,\n","   18478,\n","   2115,\n","   3029,\n","   1005,\n","   1055,\n","   7524,\n","   2000,\n","   16941,\n","   8767,\n","   5441,\n","   10738,\n","   12646,\n","   2007,\n","   16941,\n","   5427,\n","   2358,\n","   11514,\n","   9513,\n","   2015,\n","   2122,\n","   2024,\n","   2035,\n","   4276,\n","   19927,\n","   3289,\n","   1999,\n","   5094,\n","   2115,\n","   3029,\n","   25220,\n","   17171,\n","   2412,\n","   1011,\n","   20607,\n","   16941,\n","   8767,\n","   1012,\n","   2174,\n","   1010,\n","   26615,\n","   2122,\n","   13105,\n","   2064,\n","   2514,\n","   2066,\n","   1037,\n","   8667,\n","   3959,\n","   1012,\n","   2008,\n","   1005,\n","   1055,\n","   2138,\n","   1997,\n","   2028,\n","   15140,\n","   3606,\n","   2055,\n","   2087,\n","   2938,\n","   3454,\n","   1024,\n","   2027,\n","   2123,\n","   1005,\n","   1056,\n","   2147,\n","   1012,\n","   2287,\n","   1011,\n","   2214,\n","   7860,\n","   1997,\n","   2214,\n","   1011,\n","   2082,\n","   2938,\n","   2015,\n","   3151,\n","   2938,\n","   3454,\n","   2031,\n","   2146,\n","   2042,\n","   8040,\n","   22134,\n","   5498,\n","   5422,\n","   2005,\n","   2037,\n","   13720,\n","   2000,\n","   3298,\n","   15902,\n","   14260,\n","   3431,\n","   1012,\n","   1999,\n","   2755,\n","   1010,\n","   6353,\n","   1003,\n","   1997,\n","   5126,\n","   6449,\n","   2000,\n","   1000,\n","   15734,\n","   11826,\n","   2075,\n","   1000,\n","   2037,\n","   6960,\n","   1005,\n","   1055,\n","   16941,\n","   3366,\n","   10841,\n","   15780,\n","   8606,\n","   1012,\n","   2065,\n","   2017,\n","   17467,\n","   16941,\n","   3366,\n","   10841,\n","   15780,\n","   2005,\n","   2019,\n","   3029,\n","   1010,\n","   2059,\n","   2017,\n","   1005,\n","   2128,\n","   3497,\n","   5220,\n","   2007,\n","   1996,\n","   3255,\n","   2008,\n","   3310,\n","   2007,\n","   14972,\n","   2028,\n","   1010,\n","   6605,\n","   2009,\n","   1010,\n","   1998,\n","   11434,\n","   2049,\n","   8192,\n","   1012,\n","   2445,\n","   2037,\n","   3375,\n","   6447,\n","   1010,\n","   3151,\n","   2938,\n","   7300,\n","   8134,\n","   2486,\n","   2512,\n","   1011,\n","   4087,\n","   5126,\n","   2000],\n","  'attention_mask': [1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1],\n","  'start_token': 225,\n","  'end_token': 525,\n","  'article_id': 0,\n","  'title': \"Everyone's an Expert: How to Empower Your Employees for Cybersecurity Success\",\n","  'source': 'thehackernews',\n","  'date': '2024-05-01 12:03:00'},\n"," {'chunk_id': 2,\n","  'input_ids': [3431,\n","   1012,\n","   1999,\n","   2755,\n","   1010,\n","   6353,\n","   1003,\n","   1997,\n","   5126,\n","   6449,\n","   2000,\n","   1000,\n","   15734,\n","   11826,\n","   2075,\n","   1000,\n","   2037,\n","   6960,\n","   1005,\n","   1055,\n","   16941,\n","   3366,\n","   10841,\n","   15780,\n","   8606,\n","   1012,\n","   2065,\n","   2017,\n","   17467,\n","   16941,\n","   3366,\n","   10841,\n","   15780,\n","   2005,\n","   2019,\n","   3029,\n","   1010,\n","   2059,\n","   2017,\n","   1005,\n","   2128,\n","   3497,\n","   5220,\n","   2007,\n","   1996,\n","   3255,\n","   2008,\n","   3310,\n","   2007,\n","   14972,\n","   2028,\n","   1010,\n","   6605,\n","   2009,\n","   1010,\n","   1998,\n","   11434,\n","   2049,\n","   8192,\n","   1012,\n","   2445,\n","   2037,\n","   3375,\n","   6447,\n","   1010,\n","   3151,\n","   2938,\n","   7300,\n","   8134,\n","   2486,\n","   2512,\n","   1011,\n","   4087,\n","   5126,\n","   2000,\n","   2468,\n","   2440,\n","   1011,\n","   2006,\n","   21416,\n","   18738,\n","   1012,\n","   7860,\n","   2005,\n","   15631,\n","   7860,\n","   2005,\n","   5126,\n","   7860,\n","   2005,\n","   2115,\n","   3029,\n","   3375,\n","   1010,\n","   7552,\n","   2968,\n","   2003,\n","   25198,\n","   1012,\n","   4606,\n","   1010,\n","   2083,\n","   2009,\n","   2035,\n","   2027,\n","   2074,\n","   2424,\n","   3532,\n","   3463,\n","   1012,\n","   2027,\n","   1005,\n","   2128,\n","   11471,\n","   1012,\n","   16655,\n","   13807,\n","   4726,\n","   4180,\n","   2003,\n","   29172,\n","   1010,\n","   2004,\n","   2009,\n","   2987,\n","   1005,\n","   1056,\n","   2599,\n","   2000,\n","   3716,\n","   20125,\n","   1012,\n","   11771,\n","   1010,\n","   16655,\n","   13807,\n","   4726,\n","   4180,\n","   2987,\n","   1005,\n","   1056,\n","   2393,\n","   2007,\n","   3716,\n","   20125,\n","   1012,\n","   2087,\n","   2938,\n","   2015,\n","   4995,\n","   1005,\n","   1056,\n","   4621,\n","   2138,\n","   2027,\n","   1005,\n","   2128,\n","   2580,\n","   2011,\n","   2236,\n","   5130,\n","   1010,\n","   2025,\n","   2613,\n","   16941,\n","   3366,\n","   10841,\n","   15780,\n","   8519,\n","   1998,\n","   2116,\n","   2024,\n","   2881,\n","   2007,\n","   2210,\n","   7316,\n","   9859,\n","   1010,\n","   2877,\n","   2000,\n","   3132,\n","   16476,\n","   2046,\n","   3112,\n","   6165,\n","   2138,\n","   2087,\n","   2938,\n","   3454,\n","   2024,\n","   3375,\n","   2000,\n","   6133,\n","   1010,\n","   2027,\n","   1005,\n","   2128,\n","   2788,\n","   7219,\n","   2004,\n","   1037,\n","   2965,\n","   2000,\n","   2019,\n","   2203,\n","   1012,\n","   2074,\n","   4638,\n","   1037,\n","   3482,\n","   2005,\n","   12646,\n","   1998,\n","   2693,\n","   2006,\n","   1012,\n","   2021,\n","   2043,\n","   2589,\n","   2157,\n","   1010,\n","   2938,\n","   2064,\n","   2022,\n","   1037,\n","   16834,\n","   6994,\n","   2000,\n","   2393,\n","   2115,\n","   5126,\n","   2191,\n","   2062,\n","   9414,\n","   1010,\n","   2062,\n","   12753,\n","   3512,\n","   1010,\n","   3036,\n","   1011,\n","   9715,\n","   6567,\n","   1012,\n","   3198,\n","   1996,\n","   2157,\n","   3980,\n","   2077,\n","   10549,\n","   2115,\n","   2938,\n","   5576,\n","   2043,\n","   2009,\n","   3310,\n","   2000,\n","   10549,\n","   1996,\n","   2157,\n","   5576,\n","   2005,\n","   2115,\n","   3029,\n","   1010,\n","   2045,\n","   2024,\n","   2070,\n","   3980,\n","   2017,\n","   2323,\n","   2034,\n","   3198,\n","   4426,\n","   1012,\n","   2011,\n","   20077,\n","   1996,\n","   2206,\n","   1010,\n","   2017,\n","   1005,\n","   2222,\n","   2022,\n","   2488,\n","   6055,\n","   2000,\n","   7276,\n","   1996,\n","   5724,\n","   2008,\n","   2190,\n","   16142,\n","   2115,\n","   3563,\n","   3791,\n","   1012,\n","   4083,\n","   1011,\n","   2241],\n","  'attention_mask': [1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1,\n","   1],\n","  'start_token': 450,\n","  'end_token': 750,\n","  'article_id': 0,\n","  'title': \"Everyone's an Expert: How to Empower Your Employees for Cybersecurity Success\",\n","  'source': 'thehackernews',\n","  'date': '2024-05-01 12:03:00'}]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["# Let's make it a data frame"],"metadata":{"id":"Rl-z0j_cdsSC"}},{"cell_type":"code","source":["df = pd.DataFrame(all_chunks)\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379},"id":"vuzKYNITcjLh","executionInfo":{"status":"ok","timestamp":1761250460113,"user_tz":360,"elapsed":100,"user":{"displayName":"Josh Schultze","userId":"02185956454341759681"}},"outputId":"0b5c1f08-a69e-44d3-9dc3-c58da4b83d60"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   chunk_id                                          input_ids  \\\n","0         0  [101, 3071, 1005, 1055, 2019, 6739, 1024, 2129...   \n","1         1  [1010, 2027, 2342, 2000, 4553, 2129, 2000, 698...   \n","2         2  [3431, 1012, 1999, 2755, 1010, 6353, 1003, 199...   \n","3         3  [16834, 6994, 2000, 2393, 2115, 5126, 2191, 20...   \n","4         4  [2748, 1000, 2000, 2035, 1997, 1996, 2682, 101...   \n","\n","                                      attention_mask  start_token  end_token  \\\n","0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...            0        300   \n","1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          225        525   \n","2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          450        750   \n","3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          675        975   \n","4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          900       1200   \n","\n","   article_id                                              title  \\\n","0           0  Everyone's an Expert: How to Empower Your Empl...   \n","1           0  Everyone's an Expert: How to Empower Your Empl...   \n","2           0  Everyone's an Expert: How to Empower Your Empl...   \n","3           0  Everyone's an Expert: How to Empower Your Empl...   \n","4           0  Everyone's an Expert: How to Empower Your Empl...   \n","\n","          source                 date  \n","0  thehackernews  2024-05-01 12:03:00  \n","1  thehackernews  2024-05-01 12:03:00  \n","2  thehackernews  2024-05-01 12:03:00  \n","3  thehackernews  2024-05-01 12:03:00  \n","4  thehackernews  2024-05-01 12:03:00  "],"text/html":["\n","  <div id=\"df-219d92ca-72c0-4e97-8d60-8906de47945f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>chunk_id</th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>start_token</th>\n","      <th>end_token</th>\n","      <th>article_id</th>\n","      <th>title</th>\n","      <th>source</th>\n","      <th>date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[101, 3071, 1005, 1055, 2019, 6739, 1024, 2129...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>0</td>\n","      <td>300</td>\n","      <td>0</td>\n","      <td>Everyone's an Expert: How to Empower Your Empl...</td>\n","      <td>thehackernews</td>\n","      <td>2024-05-01 12:03:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>[1010, 2027, 2342, 2000, 4553, 2129, 2000, 698...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>225</td>\n","      <td>525</td>\n","      <td>0</td>\n","      <td>Everyone's an Expert: How to Empower Your Empl...</td>\n","      <td>thehackernews</td>\n","      <td>2024-05-01 12:03:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>[3431, 1012, 1999, 2755, 1010, 6353, 1003, 199...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>450</td>\n","      <td>750</td>\n","      <td>0</td>\n","      <td>Everyone's an Expert: How to Empower Your Empl...</td>\n","      <td>thehackernews</td>\n","      <td>2024-05-01 12:03:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>[16834, 6994, 2000, 2393, 2115, 5126, 2191, 20...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>675</td>\n","      <td>975</td>\n","      <td>0</td>\n","      <td>Everyone's an Expert: How to Empower Your Empl...</td>\n","      <td>thehackernews</td>\n","      <td>2024-05-01 12:03:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>[2748, 1000, 2000, 2035, 1997, 1996, 2682, 101...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>900</td>\n","      <td>1200</td>\n","      <td>0</td>\n","      <td>Everyone's an Expert: How to Empower Your Empl...</td>\n","      <td>thehackernews</td>\n","      <td>2024-05-01 12:03:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-219d92ca-72c0-4e97-8d60-8906de47945f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-219d92ca-72c0-4e97-8d60-8906de47945f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-219d92ca-72c0-4e97-8d60-8906de47945f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-48193c68-2d06-4678-9bfb-eb4668fab247\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-48193c68-2d06-4678-9bfb-eb4668fab247')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-48193c68-2d06-4678-9bfb-eb4668fab247 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 50511,\n  \"fields\": [\n    {\n      \"column\": \"chunk_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 54,\n        \"num_unique_values\": 55,\n        \"samples\": [\n          31,\n          5,\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attention_mask\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_token\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 849,\n        \"min\": 0,\n        \"max\": 12150,\n        \"num_unique_values\": 55,\n        \"samples\": [\n          6975,\n          1125,\n          7200\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_token\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 848,\n        \"min\": 23,\n        \"max\": 12356,\n        \"num_unique_values\": 2273,\n        \"samples\": [\n          2990,\n          1738,\n          391\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"article_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3806,\n        \"min\": 0,\n        \"max\": 13074,\n        \"num_unique_values\": 13075,\n        \"samples\": [\n          9128,\n          6492,\n          11846\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12732,\n        \"samples\": [\n          \"Reframing the ZTNA vs. SASE Debate\",\n          \"Cisco warns of max severity flaw in Firewall Management Center\",\n          \"Some Data Is \\u2018Breached\\u2019 During a Hacking Attack on the Alabama Education Department\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 46,\n        \"samples\": [\n          \"industrialcyber\",\n          \"checkpoint\",\n          \"wired\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 12719,\n        \"samples\": [\n          \"2024-04-01 19:10:23\",\n          \"2024-11-11 19:10:58\",\n          \"2025-05-01 11:11:40\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["#Encoding\n","\n","Writing a for loop to encode the tokens"],"metadata":{"id":"OuHEdpoNd2yQ"}},{"cell_type":"code","source":["#finding tokens to add to make \"query: \" a prefix.\n","print(tokenizer(\"query: \"))\n","print(tokenizer(\"query:\"))\n","print(tokenizer(\":\"))\n","print(tokenizer(''))\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25H-ljGneMoa","executionInfo":{"status":"ok","timestamp":1761250460152,"user_tz":360,"elapsed":37,"user":{"displayName":"Josh Schultze","userId":"02185956454341759681"}},"outputId":"e0493645-5a2b-4cb3-9a71-140a98d871b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [101, 23032, 1024, 102], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}\n","{'input_ids': [101, 23032, 1024, 102], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}\n","{'input_ids': [101, 1024, 102], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}\n","{'input_ids': [101, 102], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}\n"]}]},{"cell_type":"markdown","source":["This code adds the tokens for \"query: \" to every input_id"],"metadata":{"id":"hQ9r3BLY1VcY"}},{"cell_type":"code","source":["\n","#retrieves token IDs for 'query' directly from tokenizer\n","prefix = tokenizer(\"query: \", add_special_tokens=False)[\"input_ids\"]\n","\n","def add_prefix(ids):\n","    if isinstance(ids, list):\n","        return prefix + ids\n","    if torch.is_tensor(ids):\n","        return torch.cat([torch.tensor(prefix, dtype=torch.long, device=ids.device), ids])\n","    return ids\n","\n","df[\"input_ids\"] = df[\"input_ids\"].map(add_prefix)\n","df.head()\n","\n","\n","\n","# print(df.input_ids.iloc[0])\n","\n","# prefix = [101, 23032, 1024]\n","\n","# # build the transformed Series\n","# trimmed_input = df[\"input_ids\"].apply(\n","#     lambda ids: prefix + (ids[1:] if isinstance(ids, list) and len(ids) > 0 else ids)\n","# )\n","\n","# print(trimmed_input.head())\n","\n","# # (optional) write it back to the DataFrame\n","# df = df.copy()\n","# df[\"input_ids\"] = trimmed_input\n","\n","# df.head()\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379},"id":"GcJmanFu1Tf2","executionInfo":{"status":"ok","timestamp":1761250460377,"user_tz":360,"elapsed":223,"user":{"displayName":"Josh Schultze","userId":"02185956454341759681"}},"outputId":"e48ce57d-c299-485e-e340-73259c9ead81"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   chunk_id                                          input_ids  \\\n","0         0  [23032, 1024, 101, 3071, 1005, 1055, 2019, 673...   \n","1         1  [23032, 1024, 1010, 2027, 2342, 2000, 4553, 21...   \n","2         2  [23032, 1024, 3431, 1012, 1999, 2755, 1010, 63...   \n","3         3  [23032, 1024, 16834, 6994, 2000, 2393, 2115, 5...   \n","4         4  [23032, 1024, 2748, 1000, 2000, 2035, 1997, 19...   \n","\n","                                      attention_mask  start_token  end_token  \\\n","0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...            0        300   \n","1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          225        525   \n","2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          450        750   \n","3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          675        975   \n","4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...          900       1200   \n","\n","   article_id                                              title  \\\n","0           0  Everyone's an Expert: How to Empower Your Empl...   \n","1           0  Everyone's an Expert: How to Empower Your Empl...   \n","2           0  Everyone's an Expert: How to Empower Your Empl...   \n","3           0  Everyone's an Expert: How to Empower Your Empl...   \n","4           0  Everyone's an Expert: How to Empower Your Empl...   \n","\n","          source                 date  \n","0  thehackernews  2024-05-01 12:03:00  \n","1  thehackernews  2024-05-01 12:03:00  \n","2  thehackernews  2024-05-01 12:03:00  \n","3  thehackernews  2024-05-01 12:03:00  \n","4  thehackernews  2024-05-01 12:03:00  "],"text/html":["\n","  <div id=\"df-e6ae84af-5cd4-48a1-a9f9-7dc81422105a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>chunk_id</th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>start_token</th>\n","      <th>end_token</th>\n","      <th>article_id</th>\n","      <th>title</th>\n","      <th>source</th>\n","      <th>date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>[23032, 1024, 101, 3071, 1005, 1055, 2019, 673...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>0</td>\n","      <td>300</td>\n","      <td>0</td>\n","      <td>Everyone's an Expert: How to Empower Your Empl...</td>\n","      <td>thehackernews</td>\n","      <td>2024-05-01 12:03:00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>[23032, 1024, 1010, 2027, 2342, 2000, 4553, 21...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>225</td>\n","      <td>525</td>\n","      <td>0</td>\n","      <td>Everyone's an Expert: How to Empower Your Empl...</td>\n","      <td>thehackernews</td>\n","      <td>2024-05-01 12:03:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>[23032, 1024, 3431, 1012, 1999, 2755, 1010, 63...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>450</td>\n","      <td>750</td>\n","      <td>0</td>\n","      <td>Everyone's an Expert: How to Empower Your Empl...</td>\n","      <td>thehackernews</td>\n","      <td>2024-05-01 12:03:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>[23032, 1024, 16834, 6994, 2000, 2393, 2115, 5...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>675</td>\n","      <td>975</td>\n","      <td>0</td>\n","      <td>Everyone's an Expert: How to Empower Your Empl...</td>\n","      <td>thehackernews</td>\n","      <td>2024-05-01 12:03:00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>[23032, 1024, 2748, 1000, 2000, 2035, 1997, 19...</td>\n","      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n","      <td>900</td>\n","      <td>1200</td>\n","      <td>0</td>\n","      <td>Everyone's an Expert: How to Empower Your Empl...</td>\n","      <td>thehackernews</td>\n","      <td>2024-05-01 12:03:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6ae84af-5cd4-48a1-a9f9-7dc81422105a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e6ae84af-5cd4-48a1-a9f9-7dc81422105a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e6ae84af-5cd4-48a1-a9f9-7dc81422105a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-be61e83b-c14e-4f1a-9b49-6cb0cc2936eb\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be61e83b-c14e-4f1a-9b49-6cb0cc2936eb')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-be61e83b-c14e-4f1a-9b49-6cb0cc2936eb button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"# df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"chunk_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attention_mask\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_token\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 355,\n        \"min\": 0,\n        \"max\": 900,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          225,\n          900,\n          450\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_token\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 355,\n        \"min\": 300,\n        \"max\": 1200,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          525,\n          1200,\n          750\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"article_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Everyone's an Expert: How to Empower Your Employees for Cybersecurity Success\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"thehackernews\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2024-05-01 12:03:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["##I'm stuck here!\n","\n","Now we actually embed:"],"metadata":{"id":"vdiaS95m42yt"}},{"cell_type":"code","source":["#set model\n","def average_pool(last_hidden_states: Tensor,\n","                 attention_mask: Tensor) -> Tensor:\n","    masked = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n","    return masked.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n","\n","\n","def embed_chunks(df, model, tokenizer):\n","    model.eval()\n","    all_texts =  [\"query: \" + tokenizer.decode(ids) for ids in df[\"input_ids\"].tolist()]\n","    embeddings = []\n","    batch_size = 16\n","    for i in range(0, len(all_texts), batch_size):\n","      batch_texts = all_texts[i:i+batch_size]\n","      encoded = tokenizer(batch_texts, padding=True, truncation=True,\n","                            max_length=512, return_tensors=\"pt\")\n","      with torch.no_grad():\n","          outputs = model(**encoded)\n","      emb = average_pool(outputs.last_hidden_state, encoded[\"attention_mask\"])\n","      emb = F.normalize(emb, p=2, dim=1)\n","      embeddings.append(emb)\n","\n","    # stack all batches into one big tensor, then to numpy\n","    embeddings = torch.cat(embeddings, dim=0).numpy()\n","    print(\"shape:\", embeddings.shape)\n","    return embeddings\n","\n","\n","chunk_embeddings = embed_chunks(df, model, tokenizer)\n","\n","\n","#gen min span tree\n","# def token_to_embed(token_ids):\n","#   outputs = model(token_ids)\n","#   embeddings_with_pool = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n","#   return(embeddings_with_pool)\n","\n","# embeddings = token_to_embed(df.input_ids)\n","# len(embeddings)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"ADudpScf42O4","executionInfo":{"status":"error","timestamp":1761251208794,"user_tz":360,"elapsed":748419,"user":{"displayName":"Josh Schultze","userId":"02185956454341759681"}},"outputId":"6a1b1171-5a7c-4975-c06f-af20c4beb76a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-731096072.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mchunk_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-731096072.py\u001b[0m in \u001b[0;36membed_chunks\u001b[0;34m(df, model, tokenizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m                             max_length=512, return_tensors=\"pt\")\n\u001b[1;32m     17\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1001\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0mlayer_head_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhead_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    651\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mcache_position\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     ) -> tuple[torch.Tensor]:\n\u001b[0;32m--> 558\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mcache_position\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     ) -> tuple[torch.Tensor]:\n\u001b[0;32m--> 488\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, past_key_values, output_attentions, cache_position)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         query_layer = (\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         )\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["## Anya added ##\n","# create dataframe with article_id + embeddings\n","chunk_embeddings = pd.DataFrame({\n","    \"article_id\": df[\"article_id\"].values,\n","    \"embeddings\": list(chunk_embeddings)  # list of vectors\n","})"],"metadata":{"id":"mzOhFUf5MmzE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#safeguard to save csv before average\n","article_SBERT_embeddings_no_average_df =  df\n","article_SBERT_embeddings_no_average_df.to_csv(\"SBERT_direct_embeddings_no_average.csv\", index=False)\n","from google.colab import files\n","files.download(\"SBERT_direct_embeddings_no_average.csv\")"],"metadata":{"id":"c4P0-AfFT-Ep"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(chunk_embeddings.head())\n","\n","\n","def mean_vec(series):\n","    arrs = [np.asarray(x, dtype=float) for x in series if isinstance(x, np.ndarray)]\n","    return np.mean(np.vstack(arrs), axis=0)\n","\n","article_sbert_embeddings_df = (chunk_embeddings\n","            .groupby(\"article_id\")[\"embeddings\"]\n","            .apply(mean_vec)\n","            .reset_index(name=\"article_sbert_mean\"))\n","\n","\n","#check that it is the length of how many articles we have\n","print(article_sbert_embeddings_df.head())\n","len(article_sbert_embeddings_df)"],"metadata":{"id":"JmhiaDnqvVxu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save to csv\n","article_sbert_embeddings_df.to_csv(\"SBERT_direct_embeddings.csv\", index=False)\n","from google.colab import files\n","files.download(\"SecureBERT_dependency_embeddings.csv\")"],"metadata":{"id":"aBt_uq37vrR0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Example Use of SBERT Model\n","\n","You MUST add \"query: \" to every embedding.\n","\n","The model CAN accept multiple different texts and embed them all at the same time."],"metadata":{"id":"aQyI9tFFay5x"}},{"cell_type":"code","source":["\n","def embed(input_texts):\n","  tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-base-v2')\n","  model = AutoModel.from_pretrained('intfloat/e5-base-v2')\n","  # Tokenize the input texts\n","  batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=False, return_tensors='pt')\n","  outputs = model(**batch_dict)\n","  embeddings_with_pool = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n","  return(embeddings_with_pool)\n","\n","\n","## example\n","\n","print(embed(\"query: yo yo yo, I'm getting embedded like an OG right now!\"))\n"],"metadata":{"id":"ge53QLHnYaF6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def average_pool(last_hidden_states: Tensor,\n","                 attention_mask: Tensor) -> Tensor:\n","    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n","    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n","\n","\n","# Each input text should start with \"query: \" or \"passage: \".\n","# For tasks other than retrieval, you can simply use the \"query: \" prefix.\n","input_texts = ['query: how much protein should a female eat',\n","               'query: summit define',\n","               \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n","               \"passage: Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.\"]\n","\n","tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-base-v2')\n","model = AutoModel.from_pretrained('intfloat/e5-base-v2')\n","\n","# Tokenize the input texts\n","batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=False, return_tensors='pt')\n","\n","outputs = model(**batch_dict)\n","embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n","\n","# DO NOT NORMALIZE\n","print(f\"This is the list object form: \\n {embeddings.tolist()}\")\n","\n","#Use either a list or just the embedding object. I don't know which one I want to use yet\n","print(f\"This is the embedding object form: \\n {embeddings}\")"],"metadata":{"id":"y54qtCYyHKwE"},"execution_count":null,"outputs":[]}]}